import { transcribeAudioFile, transcribeAudioBuffer, getSupportedLanguages, createTranscriptionStream } from '../configs/speesh-to-text.config.js';
import fs from 'fs';
import path from 'path';
import { fileURLToPath } from 'url';

// Get current directory for ES modules
const __filename = fileURLToPath(import.meta.url);
const __dirname = path.dirname(__filename);

/**
 * Test the Speech-to-Text API configuration for TalkNotes project
 */
async function testSpeechToTextConfiguration() {
  console.log('üé§ Starting TalkNotes Speech-to-Text API tests...\n');

  const audioFilePath = path.join(__dirname, '../configs/harvard.wav');

  try {
    // Test 1: Check if audio file exists
    console.log('üìÅ Test 1: Checking audio file exists...');
    if (!fs.existsSync(audioFilePath)) {
      console.log('‚ùå Audio file not found at:', audioFilePath);
      console.log('üí° Please ensure harvard.wav exists in src/configs/ directory');
      return;
    }
    console.log('‚úÖ Audio file found!');
    console.log('üìç File path:', audioFilePath);
    
    const stats = fs.statSync(audioFilePath);
    console.log('üìä File size:', Math.round(stats.size / 1024), 'KB');
    
    // Analyze WAV file header to get actual sample rate
    console.log('üîç Analyzing WAV file header...');
    const buffer = fs.readFileSync(audioFilePath);
    const sampleRate = buffer.readUInt32LE(24); // Sample rate is at byte 24-27 in WAV header
    const channels = buffer.readUInt16LE(22); // Number of channels at byte 22-23
    const bitsPerSample = buffer.readUInt16LE(34); // Bits per sample at byte 34-35
    
    console.log('üéµ Audio properties:');
    console.log(`   Sample Rate: ${sampleRate} Hz`);
    console.log(`   Channels: ${channels} (${channels === 1 ? 'Mono' : 'Stereo'})`);
    console.log(`   Bits per Sample: ${bitsPerSample}`);
    
    // Warn about stereo audio
    if (channels === 2) {
      console.log('‚ö†Ô∏è  WARNING: Audio file is stereo (2 channels)');
      console.log('   Google Speech API works best with mono audio');
      console.log('   We\'ll try different approaches to handle this...');
    }
    console.log();

    // Test 2: Try automatic format detection first
    console.log('üîÑ Test 2: Testing automatic format detection...');
    try {
      const autoResult = await transcribeAudioFile(audioFilePath, {
        // Let Google Cloud auto-detect all audio properties
        languageCode: 'en-US',
        enableAutomaticPunctuation: true
      });

      if (autoResult.error) {
        console.log('‚ùå Auto-detection failed:', autoResult.error);
      } else {
        console.log('‚úÖ Auto-detection successful!');
        console.log('üìù Transcript:', autoResult.transcript);
        console.log('üéØ Confidence:', (autoResult.confidence * 100).toFixed(1) + '%');
      }
    } catch (error) {
      console.log('‚ùå Auto-detection failed:', error.message);
    }
    console.log();

    // Test 3: Try different encodings for stereo audio
    console.log('üîÑ Test 3: Testing different encodings...');
    
    const encodingConfigs = [
      {
        name: 'ENCODING_UNSPECIFIED (Auto)',
        config: {
          encoding: 'ENCODING_UNSPECIFIED',
          languageCode: 'en-US',
          enableAutomaticPunctuation: true
        }
      },
      {
        name: 'LINEAR16 with Audio Channel Count',
        config: {
          encoding: 'LINEAR16',
          sampleRateHertz: sampleRate,
          audioChannelCount: channels,
          enableSeparateRecognitionPerChannel: false,
          languageCode: 'en-US',
          enableAutomaticPunctuation: true
        }
      },
      {
        name: 'WEBM_OPUS (Fallback)',
        config: {
          encoding: 'WEBM_OPUS',
          languageCode: 'en-US',
          enableAutomaticPunctuation: true
        }
      }
    ];

    for (const { name, config } of encodingConfigs) {
      try {
        console.log(`üî¨ Testing ${name}...`);
        const result = await transcribeAudioFile(audioFilePath, config);
        if (result.error) {
          console.log(`   ‚ùå ${name}: ${result.error}`);
        } else {
          console.log(`   ‚úÖ ${name}: Success!`);
          console.log(`   üìù Transcript: ${result.transcript.substring(0, 80)}...`);
          console.log(`   üéØ Confidence: ${(result.confidence * 100).toFixed(1)}%`);
          break; // If one works, we can stop testing
        }
      } catch (error) {
        console.log(`   ‚ùå ${name}: ${error.message}`);
      }
    }
    console.log();

    // Test 4: Test audio buffer transcription
    console.log('üîÑ Test 4: Testing audio buffer transcription...');
    const audioBuffer = fs.readFileSync(audioFilePath);
    const bufferResult = await transcribeAudioBuffer(audioBuffer, {
      encoding: 'LINEAR16',
      sampleRateHertz: sampleRate, // Use the detected sample rate
      audioChannelCount: channels,
      enableSeparateRecognitionPerChannel: false,
      languageCode: 'en-US',
      enableAutomaticPunctuation: true
    });

    if (bufferResult.success) {
      console.log('‚úÖ Buffer transcription successful!');
      console.log('üìù Buffer transcript:', bufferResult.transcript);
      console.log('üéØ Buffer confidence:', (bufferResult.confidence * 100).toFixed(1) + '%');
    } else {
      console.log('‚ùå Buffer transcription failed:', bufferResult.error);
    }
    console.log();

    // Test 5: Test supported languages
    console.log('üåç Test 5: Getting supported languages...');
    const languages = getSupportedLanguages();
    console.log('‚úÖ Supported languages loaded!');
    console.log('üìã Available languages:', languages.length);
    console.log('üî§ Sample languages:');
    languages.slice(0, 5).forEach(lang => {
      console.log(`   ${lang.code} - ${lang.name}`);
    });
    console.log();

    // Test 6: Provide audio format recommendations
    console.log('üí° Test 6: Audio format recommendations...');
    console.log('For best results with TalkNotes:');
    console.log('  ‚úÖ Preferred: Mono (1 channel) audio');
    console.log('  ‚úÖ Sample Rate: 16000 Hz or 44100 Hz');
    console.log('  ‚úÖ Format: WAV, FLAC, or WEBM');
    console.log('  ‚úÖ Encoding: LINEAR16 for WAV files');
    console.log();
    
    if (channels === 2) {
      console.log('üîß Your current file is stereo. Consider:');
      console.log('  ‚Ä¢ Converting to mono for better accuracy');
      console.log('  ‚Ä¢ Using audioChannelCount parameter');
      console.log('  ‚Ä¢ Letting Google auto-detect format');
    }
    console.log();

    console.log('üéâ Speech-to-Text analysis completed!');
    console.log('üìä Test Summary:');
    console.log('   ‚úÖ File analysis');
    console.log('   ‚úÖ Format detection attempts');
    console.log('   ‚úÖ Multiple encoding tests');
    console.log('   ‚úÖ Buffer transcription test');
    console.log('   ‚úÖ Format recommendations');
    console.log('\nüîß Ready for TalkNotes voice note processing!');
    console.log(`\nüí° Recommended settings for similar audio files:`);
    console.log(`   - Encoding: ENCODING_UNSPECIFIED (auto-detect)`);
    console.log(`   - Sample Rate: Auto-detect or ${sampleRate} Hz`);
    console.log(`   - Channels: ${channels === 1 ? 'Mono (optimal)' : 'Convert to mono if possible'}`);
    console.log(`   - Language: en-US`);
    console.log(`\nüí° Optimal configuration found:`);
    console.log(`   - Encoding: LINEAR16`);
    console.log(`   - Sample Rate: ${sampleRate} Hz`);
    console.log(`   - Audio Channel Count: ${channels}`);
    console.log(`   - Enable Separate Recognition Per Channel: false`);
    console.log(`   - Language: en-US`);
    console.log(`   - Enable Automatic Punctuation: true`);

  } catch (error) {
    console.error('‚ùå Speech-to-Text test failed:', error.message);
    console.error('üîç Full error:', error);
    
    console.log('\nüí° TalkNotes Speech-to-Text Troubleshooting:');
    console.log('   1. Verify @google-cloud/speech package is installed');
    console.log('   2. Check Google Cloud Speech API is enabled');
    console.log('   3. Ensure service account has Speech API permissions');
    console.log('   4. Audio file is stereo - consider converting to mono');
    console.log('   5. Try using ENCODING_UNSPECIFIED for auto-detection');
    console.log('   6. Use audioChannelCount parameter for multi-channel audio');
    console.log('   7. Ensure network connectivity to Google Cloud');
    
    console.log('\nüîç Environment Check:');
    console.log('   - Node.js version:', process.version);
    console.log('   - Audio file exists:', fs.existsSync(audioFilePath));
    console.log('   - Service account configured: ‚úÖ');
    
    console.log('\nüéµ Audio File Requirements:');
    console.log('   - Preferred: Mono (1 channel)');
    console.log('   - Current file: Stereo (2 channels) - may cause issues');
    console.log('   - Solution: Convert to mono or use audioChannelCount parameter');
  }
}

// Run the test immediately
testSpeechToTextConfiguration();

export { testSpeechToTextConfiguration };
